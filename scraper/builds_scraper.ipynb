{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 32-bit ('pcpartpicker-scrape': pipenv)",
   "display_name": "Python 3.8.2 32-bit ('pcpartpicker-scrape': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "28e31fb0893a0fe1ff445348b3c448ef8c51c4e5415cde30176f832e910ccf9d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import traceback\n",
    "from random import randint\n",
    "from itertools import cycle\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from builds_links_scraper import get_links\n",
    "from selenium.webdriver.firefox.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsed_url(page = 1, low_range=250, up_range=5000, build_link = None):\n",
    "    base_url = 'https://pcpartpicker.com'\n",
    "    if build_link == None:\n",
    "        fragment = f'/builds/#B=1&page={page}&X={low_range}00,{up_range}00'\n",
    "    else: \n",
    "        fragment = f'{build_link}'\n",
    "\n",
    "    return f'{base_url}{fragment}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price(price):\n",
    "    if price[0] == '$':\n",
    "        price = price.replace('$', '').strip()\n",
    "        if len(price.split(' ')) > 1:\n",
    "            return False\n",
    "    else: \n",
    "        return False\n",
    "\n",
    "    return float(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_scraper(url, user_agent):\n",
    "    builds_dict = {}\n",
    "    build_comps = ['Name','CPU', 'CPU Cooler', 'Motherboard', 'Memory', 'Storage', 'Video Card', 'Case', 'Power Supply', 'Build Price']\n",
    "\n",
    "    try:\n",
    "        rq = requests.get(url, headers=user_agent)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return builds_dict\n",
    "\n",
    "    soup = BeautifulSoup(rq.content, 'html.parser')\n",
    "    builds_dict['Name'] = soup.find('h1', {\"class\": \"build__name\"}).text\n",
    "    comp_table_rows = soup.find('table', {\"class\": \"partlist partlist--mini\"}).find_all('tr')\n",
    "    extra_price = 0\n",
    "\n",
    "    # Two rows is one component, one for the name of the comp and other for the features\n",
    "    row_it = iter(comp_table_rows)\n",
    "    for name, component in zip(row_it, row_it):\n",
    "        try:\n",
    "            name_text = name.find('h4').text.strip()\n",
    "            # Getting the name and price components\n",
    "            component_el = component.find('td', {'class':'td__name'}).findChildren(text=True)\n",
    "            component_el = list(filter(lambda el: el != '\\n', component_el))\n",
    "\n",
    "            if len(component_el) == 2:\n",
    "                comp_name = component_el[0]\n",
    "                comp_price = clean_price(component_el[1])\n",
    "                # If price isn't in USD\n",
    "                if not comp_price: \n",
    "                    return {}\n",
    "            else:\n",
    "                comp_name, comp_price = *component_el, None\n",
    "\n",
    "            # If the component are in the selected list for scrape\n",
    "            if name_text in build_comps:\n",
    "                comp_els = {'Name': comp_name, 'Price': comp_price}\n",
    "\n",
    "                if name_text not in builds_dict:\n",
    "                    builds_dict[name_text] = comp_els\n",
    "                else:\n",
    "                    comp_copy = builds_dict[name_text].copy()\n",
    "                    builds_dict[name_text] = []\n",
    "                    builds_dict[name_text].extend([comp_els, comp_copy])\n",
    "            else:\n",
    "                # Calculate the total of the components not taken into account\n",
    "                extra_price += comp_price if isinstance(comp_price, float) else 0\n",
    "\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e, url, name_text, component_el)\n",
    "            continue\n",
    "\n",
    "        total_table_row = soup.find('table', {\"class\": \"block partlist partlist--mini partlist--totals\"}).find('td', {\"class\": \"td__price\"}).text\n",
    "        builds_dict['Build Price'] = round(float(total_table_row.replace('$', '')) - extra_price, 2)\n",
    "    \n",
    "    return builds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    user_agent = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:80.0) Gecko/20100101 Firefox/80.0'}\n",
    "    builds_links = get_links()\n",
    "    n_pages = 1\n",
    "    builds_list = [] \n",
    "\n",
    "    for build in builds_links[:1]:\n",
    "        try:\n",
    "            build_url = parsed_url(build_link=build['link'])\n",
    "            build_dict = build_scraper(build_url, user_agent)\n",
    "\n",
    "            # If the build was scraped correctly\n",
    "            if build_dict:\n",
    "                builds_list.append(build_dict)\n",
    "\n",
    "            delay = randint(2, 10)  \n",
    "            time.sleep(delay)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(traceback.format_exc())\n",
    "            continue\n",
    "\n",
    "    return builds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    builds = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[{'Build Price': 1986.0,\n  'CPU': {'Name': 'Intel Core i9-9900K 3.6 GHz 8-Core', 'Price': 379.99},\n  'CPU Cooler': {'Name': 'Corsair iCUE H150i RGB PRO XT 75 CFM Liquid',\n                 'Price': 159.99},\n  'Case': {'Name': 'MSI Gungnir 100 ATX Mid Tower', 'Price': 109.99},\n  'Memory': {'Name': 'Corsair Vengeance RGB Pro 32 GB (2 x 16 GB) DDR4-3200 '\n                     'CL16',\n             'Price': 142.99},\n  'Motherboard': {'Name': 'MSI MPG Z390 GAMING PRO CARBON AC ATX LGA1151',\n                  'Price': 225.99},\n  'Name': \"Ryland's PC\",\n  'Power Supply': {'Name': 'ADATA XPG CORE Reactor 850 W 80+ Gold Certified '\n                           'Fully Modular ATX',\n                   'Price': 158.16},\n  'Storage': [{'Name': 'Western Digital BLACK SERIES 2 TB 3.5\" 7200RPM',\n               'Price': 99.84},\n              [{'Name': 'Crucial P1 1 TB M.2-2280 NVME SSD', 'Price': 104.12},\n               {'Name': 'Western Digital Blue 1 TB 2.5\" SSD', 'Price': 99.99}]],\n  'Video Card': {'Name': 'MSI GeForce RTX 2070 8 GB VENTUS GP',\n                 'Price': 504.94}}]\n"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(builds)"
   ]
  }
 ]
}