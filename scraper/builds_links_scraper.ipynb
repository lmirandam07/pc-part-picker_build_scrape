{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 32-bit ('pcpartpicker-scrape': pipenv)",
   "display_name": "Python 3.8.2 32-bit ('pcpartpicker-scrape': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "28e31fb0893a0fe1ff445348b3c448ef8c51c4e5415cde30176f832e910ccf9d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import utilities\n",
    "import traceback\n",
    "from random import randint\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver(proxy=None, user_agent=None):\n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "\n",
    "    if proxy:\n",
    "        options.add_argument(f'--proxy-server={proxy}')\n",
    "    if user_agent:\n",
    "        options.add_argument(f'--user_agent={user_agent}')\n",
    "\n",
    "    firefox_profile = webdriver.FirefoxProfile()\n",
    "    firefox_profile.set_preference('permissions.default.image', 2)\n",
    "    firefox_profile.set_preference('dom.ipc.plugins.enabled.libflashplayer.so', 'false')\n",
    "    browser = webdriver.Firefox(options=options, firefox_profile=firefox_profile)\n",
    "\n",
    "    return browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links():\n",
    "    num_pages = 1\n",
    "    user_agent = utilities.get_user_agent()\n",
    "    file_name = 'builds_links.txt'\n",
    "    builds_links = []\n",
    "    for i in range(1, num_pages+1):\n",
    "        try:\n",
    "            url = utilities.parse_url(page=i)\n",
    "            browser = get_driver(user_agent=user_agent)\n",
    "            browser.get(url)\n",
    "            time.sleep(randint(2, 5))\n",
    "            soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "            # Get the link of all build cards in a single page\n",
    "            builds_links_el = soup.find_all(\"a\", {\"class\": \"logGroup__target\"}, href=True)\n",
    "            builds_links = [a['href'] for a in builds_links_el]\n",
    "            browser.close()\n",
    "        except Exception as e:\n",
    "            browser.close()\n",
    "            print(traceback.format_exc())\n",
    "            continue\n",
    "\n",
    "    if not os.path.exists(f'./{file_name}'):\n",
    "        # Save build href in a text file\n",
    "        with open(f'{file_name}', 'w') as f:\n",
    "            for build in builds_links:\n",
    "                f.write(str(build) + '\\n')\n",
    "    else:\n",
    "        with open(f'{file_name}', 'r+') as f:\n",
    "            new_builds = []\n",
    "            content = f.read()\n",
    "            for build in builds_links:\n",
    "                f.seek(0, 0)\n",
    "                if build not in content:\n",
    "                    new_builds.append(build)\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            if new_builds:\n",
    "                f.seek(0, 0)\n",
    "                f.writelines(str(b + '\\n') for b in new_builds)\n",
    "                f.write(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    get_links()"
   ]
  }
 ]
}